2025-04-28 23:29:47,422 - INFO - Registered tool: add_two_numbers
2025-04-28 23:29:47,422 - INFO - Registered tool: multiply_two_numbers
2025-04-28 23:29:56,199 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-28 23:29:56,200 - INFO - Executed add_two_numbers with args {'a': '10', 'b': '10'}, result: 20
2025-04-28 23:29:56,395 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-28 23:30:04,041 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-28 23:30:04,042 - INFO - Executed multiply_two_numbers with args {'a': '10', 'b': '10'}, result: 100
2025-04-28 23:30:04,939 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-28 23:30:21,037 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-28 23:30:21,037 - INFO - Executed multiply_two_numbers with args {'a': '10', 'b': '20'}, result: 200
2025-04-28 23:30:22,204 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-28 23:40:24,071 - INFO - Registered tool: add_two_numbers
2025-04-28 23:40:24,071 - INFO - Registered tool: multiply_two_numbers
2025-04-28 23:40:24,071 - INFO - Registered tool: concat_text
2025-04-28 23:40:24,071 - INFO - Registered tool: sum_list
2025-04-28 23:40:24,071 - INFO - Registered tool: reverse_text
2025-04-28 23:40:24,071 - INFO - Registered tool: get_current_time
2025-04-28 23:40:27,724 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-28 23:40:27,725 - INFO - Executed add_two_numbers with args {'a': '12', 'b': '34'}, result: 46
2025-04-28 23:40:29,079 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-28 23:40:37,202 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-28 23:40:37,202 - INFO - Executed multiply_two_numbers with args {'a': '7', 'b': '8'}, result: 56
2025-04-28 23:40:39,572 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-28 23:40:44,162 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-28 23:40:44,162 - INFO - Executed concat_text with args {'text1': 'Merhaba ', 'text2': 'Dúnya'}, result: Merhaba Dúnya
2025-04-28 23:40:46,796 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-28 23:41:02,236 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-28 23:41:02,237 - INFO - Executed reverse_text with args {'text': 'Ollama harika'}, result: akirah amallO
2025-04-28 23:41:05,936 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-28 23:41:10,629 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-28 23:41:10,630 - INFO - Executed get_current_time with args {'format': '%H:%M:%S'}, result: 23:41:10
2025-04-28 23:41:19,449 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-28 23:41:24,041 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-28 23:41:24,042 - INFO - Executed get_current_time with args {'format': '%Y-%m-%d'}, result: 2025-04-28
2025-04-28 23:41:29,453 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-28 23:42:30,375 - INFO - Registered tool: add_two_numbers
2025-04-28 23:42:30,375 - INFO - Registered tool: multiply_two_numbers
2025-04-28 23:42:30,375 - INFO - Registered tool: concat_text
2025-04-28 23:42:30,375 - INFO - Registered tool: sum_list
2025-04-28 23:42:30,375 - INFO - Registered tool: reverse_text
2025-04-28 23:42:30,375 - INFO - Registered tool: get_current_time
2025-04-28 23:42:30,375 - INFO - Registered tool: fetch_arxiv_april_2025
2025-04-28 23:42:50,828 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-28 23:42:51,364 - INFO - Executed fetch_arxiv_april_2025 with args {'max_results': 10, 'query': 'artificial intelligence'}, result: []
2025-04-28 23:43:02,475 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-28 23:43:39,465 - INFO - Registered tool: add_two_numbers
2025-04-28 23:43:39,465 - INFO - Registered tool: multiply_two_numbers
2025-04-28 23:43:39,465 - INFO - Registered tool: concat_text
2025-04-28 23:43:39,465 - INFO - Registered tool: sum_list
2025-04-28 23:43:39,465 - INFO - Registered tool: reverse_text
2025-04-28 23:43:39,465 - INFO - Registered tool: get_current_time
2025-04-28 23:43:39,465 - INFO - Registered tool: fetch_arxiv_april_2025
2025-04-28 23:44:06,202 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-28 23:44:07,034 - INFO - Executed fetch_arxiv_april_2025 with args {'max_results': '100', 'query': ''}, result: []
2025-04-28 23:45:45,972 - INFO - Registered tool: add_two_numbers
2025-04-28 23:45:45,972 - INFO - Registered tool: multiply_two_numbers
2025-04-28 23:45:45,972 - INFO - Registered tool: concat_text
2025-04-28 23:45:45,972 - INFO - Registered tool: sum_list
2025-04-28 23:45:45,972 - INFO - Registered tool: reverse_text
2025-04-28 23:45:45,972 - INFO - Registered tool: get_current_time
2025-04-28 23:45:45,972 - INFO - Registered tool: fetch_arxiv_april_2025
2025-04-28 23:45:52,559 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-28 23:45:53,088 - INFO - Executed fetch_arxiv_april_2025 with args {'max_results': '10', 'query': 'quantum computing'}, result: []
2025-04-28 23:46:25,720 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-28 23:46:26,205 - INFO - Executed fetch_arxiv_april_2025 with args {'max_results': '10', 'query': 'Artificial Intelligence'}, result: []
2025-04-28 23:47:26,768 - INFO - Registered tool: add_two_numbers
2025-04-28 23:47:26,768 - INFO - Registered tool: multiply_two_numbers
2025-04-28 23:47:26,768 - INFO - Registered tool: concat_text
2025-04-28 23:47:26,768 - INFO - Registered tool: sum_list
2025-04-28 23:47:26,768 - INFO - Registered tool: reverse_text
2025-04-28 23:47:26,768 - INFO - Registered tool: get_current_time
2025-04-28 23:47:26,768 - INFO - Registered tool: fetch_arxiv_april_2025
2025-04-28 23:47:32,840 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-28 23:47:32,842 - ERROR - Invalid parameters for 'fetch_arxiv_april_2025': 1 validation error for ArxivApril2025Schema
max_results
  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='null', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/int_parsing
2025-04-28 23:49:23,011 - INFO - Registered tool: add_two_numbers
2025-04-28 23:49:23,011 - INFO - Registered tool: multiply_two_numbers
2025-04-28 23:49:23,011 - INFO - Registered tool: concat_text
2025-04-28 23:49:23,011 - INFO - Registered tool: sum_list
2025-04-28 23:49:23,011 - INFO - Registered tool: reverse_text
2025-04-28 23:49:23,011 - INFO - Registered tool: get_current_time
2025-04-28 23:49:23,011 - INFO - Registered tool: fetch_arxiv_april_2025
2025-04-28 23:49:26,415 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-28 23:49:26,895 - INFO - Executed fetch_arxiv_april_2025 with args {'max_results': '0', 'query': 'Artificial Intelligence'}, result: [{'status': 'no_results', 'message': "No papers found for 'Artificial Intelligence' in April 2025", 'query': 'Artificial Intelligence', 'date_range': '2025-04-01 to 2025-04-30'}]
2025-04-28 23:51:37,664 - INFO - Registered tool: add_two_numbers
2025-04-28 23:51:37,664 - INFO - Registered tool: multiply_two_numbers
2025-04-28 23:51:37,664 - INFO - Registered tool: concat_text
2025-04-28 23:51:37,664 - INFO - Registered tool: sum_list
2025-04-28 23:51:37,664 - INFO - Registered tool: reverse_text
2025-04-28 23:51:37,664 - INFO - Registered tool: get_current_time
2025-04-28 23:51:37,664 - INFO - Registered tool: fetch_recent_arxiv
2025-04-28 23:51:45,972 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-28 23:51:46,538 - INFO - Executed fetch_recent_arxiv with args {'category': 'cs.AI', 'query': ''}, result: [{'title': 'Generalization Capability for Imitation Learning', 'summary': 'Imitation learning holds the promise of equipping robots with versatile\nskills by learning from expert demonstrations. However, policies trained on\nfinite datasets often struggle to generalize beyond the training distribution.\nIn this work, we present a unified perspective on the generalization capability\nof imitation learning, grounded in both information theorey and data\ndistribution property. We first show that the generalization gap can be upper\nbounded by (i) the conditional information bottleneck on intermediate\nrepresentations and (ii) the mutual information between the model parameters\nand the training dataset. This characterization provides theoretical guidance\nfor designing effective training strategies in imitation learning, particularly\nin determining whether to freeze, fine-tune, or train large pretrained encoders\n(e.g., vision-language models or vision foundation models) from scratch to\nachieve better generalization. Furthermore, we demonstrate that high\nconditional entropy from input to output induces a flatter likelihood\nlandscape, thereby reducing the upper bound on the generalization gap. In\naddition, it shortens the stochastic gradient descent (SGD) escape time from\nsharp local minima, which may increase the likelihood of reaching global optima\nunder fixed optimization budgets. These insights explain why imitation learning\noften exhibits limited generalization and underscore the importance of not only\nscaling the diversity of input data but also enriching the variability of\noutput labels conditioned on the same input.', 'published': '2025-04-25T17:59:59Z', 'pdf_link': 'http://arxiv.org/pdf/2504.18538v1', 'html_link': 'http://arxiv.org/abs/2504.18538v1', 'categories': ['cs.LG']}, {'title': 'Adapting Probabilistic Risk Assessment for AI', 'summary': "Modern general-purpose artificial intelligence (AI) systems present an urgent\nrisk management challenge, as their rapidly evolving capabilities and potential\nfor catastrophic harm outpace our ability to reliably assess their risks.\nCurrent methods often rely on selective testing and undocumented assumptions\nabout risk priorities, frequently failing to make a serious attempt at\nassessing the set of pathways through which Al systems pose direct or indirect\nrisks to society and the biosphere. This paper introduces the probabilistic\nrisk assessment (PRA) for AI framework, adapting established PRA techniques\nfrom high-reliability industries (e.g., nuclear power, aerospace) for the new\nchallenges of advanced AI. The framework guides assessors in identifying\npotential risks, estimating likelihood and severity, and explicitly documenting\nevidence, underlying assumptions, and analyses at appropriate granularities.\nThe framework's implementation tool synthesizes the results into a risk report\ncard with aggregated risk estimates from all assessed risks. This systematic\napproach integrates three advances: (1) Aspect-oriented hazard analysis\nprovides systematic hazard coverage guided by a first-principles taxonomy of AI\nsystem aspects (e.g. capabilities, domain knowledge, affordances); (2) Risk\npathway modeling analyzes causal chains from system aspects to societal impacts\nusing bidirectional analysis and incorporating prospective techniques; and (3)\nUncertainty management employs scenario decomposition, reference scales, and\nexplicit tracing protocols to structure credible projections with novelty or\nlimited data. Additionally, the framework harmonizes diverse assessment methods\nby integrating evidence into comparable, quantified absolute risk estimates for\ncritical decisions. We have implemented this as a workbook tool for AI\ndevelopers, evaluators, and regulators, available on the project website.", 'published': '2025-04-25T17:59:14Z', 'pdf_link': 'http://arxiv.org/pdf/2504.18536v1', 'html_link': 'http://arxiv.org/abs/2504.18536v1', 'categories': ['cs.AI']}, {'title': 'Scaling Laws For Scalable Oversight', 'summary': 'Scalable oversight, the process by which weaker AI systems supervise stronger\nones, has been proposed as a key strategy to control future superintelligent\nsystems. However, it is still unclear how scalable oversight itself scales. To\naddress this gap, we propose a framework that quantifies the probability of\nsuccessful oversight as a function of the capabilities of the overseer and the\nsystem being overseen. Specifically, our framework models oversight as a game\nbetween capability-mismatched players; the players have oversight-specific and\ndeception-specific Elo scores that are a piecewise-linear function of their\ngeneral intelligence, with two plateaus corresponding to task incompetence and\ntask saturation. We validate our framework with a modified version of the game\nNim and then apply it to four oversight games: "Mafia", "Debate", "Backdoor\nCode" and "Wargames". For each game, we find scaling laws that approximate how\ndomain performance depends on general AI system capability (using Chatbot Arena\nElo as a proxy for general capability). We then build on our findings in a\ntheoretical study of Nested Scalable Oversight (NSO), a process in which\ntrusted models oversee untrusted stronger models, which then become the trusted\nmodels in the next step. We identify conditions under which NSO succeeds and\nderive numerically (and in some cases analytically) the optimal number of\noversight levels to maximize the probability of oversight success. In our\nnumerical examples, the NSO success rate is below 52% when overseeing systems\nthat are 400 Elo points stronger than the baseline overseer, and it declines\nfurther for overseeing even stronger systems.', 'published': '2025-04-25T17:54:27Z', 'pdf_link': 'http://arxiv.org/pdf/2504.18530v1', 'html_link': 'http://arxiv.org/abs/2504.18530v1', 'categories': ['cs.AI']}, {'title': 'DeSIA: Attribute Inference Attacks Against Limited Fixed Aggregate\n  Statistics', 'summary': 'Empirical inference attacks are a popular approach for evaluating the privacy\nrisk of data release mechanisms in practice. While an active attack literature\nexists to evaluate machine learning models or synthetic data release, we\ncurrently lack comparable methods for fixed aggregate statistics, in particular\nwhen only a limited number of statistics are released. We here propose an\ninference attack framework against fixed aggregate statistics and an attribute\ninference attack called DeSIA. We instantiate DeSIA against the U.S. Census\nPPMF dataset and show it to strongly outperform reconstruction-based attacks.\nIn particular, we show DeSIA to be highly effective at identifying vulnerable\nusers, achieving a true positive rate of 0.14 at a false positive rate of\n$10^{-3}$. We then show DeSIA to perform well against users whose attributes\ncannot be verified and when varying the number of aggregate statistics and\nlevel of noise addition. We also perform an extensive ablation study of DeSIA\nand show how DeSIA can be successfully adapted to the membership inference\ntask. Overall, our results show that aggregation alone is not sufficient to\nprotect privacy, even when a relatively small number of aggregates are being\nreleased, and emphasize the need for formal privacy mechanisms and testing\nbefore aggregate statistics are released.', 'published': '2025-04-25T17:10:33Z', 'pdf_link': 'http://arxiv.org/pdf/2504.18497v1', 'html_link': 'http://arxiv.org/abs/2504.18497v1', 'categories': ['cs.CR']}, {'title': 'Action Flow Matching for Continual Robot Learning', 'summary': "Continual learning in robotics seeks systems that can constantly adapt to\nchanging environments and tasks, mirroring human adaptability. A key challenge\nis refining dynamics models, essential for planning and control, while\naddressing issues such as safe adaptation, catastrophic forgetting, outlier\nmanagement, data efficiency, and balancing exploration with exploitation -- all\nwithin task and onboard resource constraints. Towards this goal, we introduce a\ngenerative framework leveraging flow matching for online robot dynamics model\nalignment. Rather than executing actions based on a misaligned model, our\napproach refines planned actions to better match with those the robot would\ntake if its model was well aligned. We find that by transforming the actions\nthemselves rather than exploring with a misaligned model -- as is traditionally\ndone -- the robot collects informative data more efficiently, thereby\naccelerating learning. Moreover, we validate that the method can handle an\nevolving and possibly imperfect model while reducing, if desired, the\ndependency on replay buffers or legacy model snapshots. We validate our\napproach using two platforms: an unmanned ground vehicle and a quadrotor. The\nresults highlight the method's adaptability and efficiency, with a record\n34.2\\% higher task success rate, demonstrating its potential towards enabling\ncontinual robot learning. Code:\nhttps://github.com/AlejandroMllo/action_flow_matching.", 'published': '2025-04-25T16:26:15Z', 'pdf_link': 'http://arxiv.org/pdf/2504.18471v1', 'html_link': 'http://arxiv.org/abs/2504.18471v1', 'categories': ['cs.RO']}, {'title': 'Fast-Slow Thinking for Large Vision-Language Model Reasoning', 'summary': 'Recent advances in large vision-language models (LVLMs) have revealed an\n\\textit{overthinking} phenomenon, where models generate verbose reasoning\nacross all tasks regardless of questions. To address this issue, we present\n\\textbf{FAST}, a novel \\textbf{Fa}st-\\textbf{S}low \\textbf{T}hinking framework\nthat dynamically adapts reasoning depth based on question characteristics.\nThrough empirical analysis, we establish the feasibility of fast-slow thinking\nin LVLMs by investigating how response length and data distribution affect\nperformance. We develop FAST-GRPO with three components: model-based metrics\nfor question characterization, an adaptive thinking reward mechanism, and\ndifficulty-aware KL regularization. Experiments across seven reasoning\nbenchmarks demonstrate that FAST achieves state-of-the-art accuracy with over\n10\\% relative improvement compared to the base model, while reducing token\nusage by 32.7-67.3\\% compared to previous slow-thinking approaches, effectively\nbalancing reasoning length and accuracy.', 'published': '2025-04-25T16:11:23Z', 'pdf_link': 'http://arxiv.org/pdf/2504.18458v1', 'html_link': 'http://arxiv.org/abs/2504.18458v1', 'categories': ['cs.CL']}, {'title': 'Reason Like a Radiologist: Chain-of-Thought and Reinforcement Learning\n  for Verifiable Report Generation', 'summary': "Radiology report generation is critical for efficiency but current models\nlack the structured reasoning of experts, hindering clinical trust and\nexplainability by failing to link visual findings to precise anatomical\nlocations. This paper introduces BoxMed-RL, a groundbreaking unified training\nframework for generating spatially verifiable and explainable radiology\nreports. Built on a large vision-language model, BoxMed-RL revolutionizes\nreport generation through two integrated phases: (1) In the Pretraining Phase,\nwe refine the model via medical concept learning, using Chain-of-Thought\nsupervision to internalize the radiologist-like workflow, followed by spatially\nverifiable reinforcement, which applies reinforcement learning to align medical\nfindings with bounding boxes. (2) In the Downstream Adapter Phase, we freeze\nthe pretrained weights and train a downstream adapter to ensure fluent and\nclinically credible reports. This framework precisely mimics radiologists'\nworkflow, compelling the model to connect high-level medical concepts with\ndefinitive anatomical evidence. Extensive experiments on public datasets\ndemonstrate that BoxMed-RL achieves an average 7% improvement in both METEOR\nand ROUGE-L metrics compared to state-of-the-art methods. An average 5%\nimprovement in large language model-based metrics further underscores\nBoxMed-RL's robustness in generating high-quality radiology reports.", 'published': '2025-04-25T16:05:06Z', 'pdf_link': 'http://arxiv.org/pdf/2504.18453v1', 'html_link': 'http://arxiv.org/abs/2504.18453v1', 'categories': ['cs.AI']}, {'title': 'Iterative Event-based Motion Segmentation by Variational Contrast\n  Maximization', 'summary': 'Event cameras provide rich signals that are suitable for motion estimation\nsince they respond to changes in the scene. As any visual changes in the scene\nproduce event data, it is paramount to classify the data into different motions\n(i.e., motion segmentation), which is useful for various tasks such as object\ndetection and visual servoing. We propose an iterative motion segmentation\nmethod, by classifying events into background (e.g., dominant motion\nhypothesis) and foreground (independent motion residuals), thus extending the\nContrast Maximization framework. Experimental results demonstrate that the\nproposed method successfully classifies event clusters both for public and\nself-recorded datasets, producing sharp, motion-compensated edge-like images.\nThe proposed method achieves state-of-the-art accuracy on moving object\ndetection benchmarks with an improvement of over 30%, and demonstrates its\npossibility of applying to more complex and noisy real-world scenes. We hope\nthis work broadens the sensitivity of Contrast Maximization with respect to\nboth motion parameters and input events, thus contributing to theoretical\nadvancements in event-based motion segmentation estimation.\nhttps://github.com/aoki-media-lab/event_based_segmentation_vcmax', 'published': '2025-04-25T16:00:23Z', 'pdf_link': 'http://arxiv.org/pdf/2504.18447v1', 'html_link': 'http://arxiv.org/abs/2504.18447v1', 'categories': ['cs.CV']}, {'title': 'Pseudo-Boolean Proof Logging for Optimal Classical Planning', 'summary': 'We introduce lower-bound certificates for classical planning tasks, which can\nbe used to prove the unsolvability of a task or the optimality of a plan in a\nway that can be verified by an independent third party. We describe a general\nframework for generating lower-bound certificates based on pseudo-Boolean\nconstraints, which is agnostic to the planning algorithm used.\n  As a case study, we show how to modify the $A^{*}$ algorithm to produce\nproofs of optimality with modest overhead, using pattern database heuristics\nand $h^\\textit{max}$ as concrete examples. The same proof logging approach\nworks for any heuristic whose inferences can be efficiently expressed as\nreasoning over pseudo-Boolean constraints.', 'published': '2025-04-25T15:54:09Z', 'pdf_link': 'http://arxiv.org/pdf/2504.18443v1', 'html_link': 'http://arxiv.org/abs/2504.18443v1', 'categories': ['cs.AI']}, {'title': 'Enhancing Pre-Trained Model-Based Class-Incremental Learning through\n  Neural Collapse', 'summary': 'Class-Incremental Learning (CIL) is a critical capability for real-world\napplications, enabling learning systems to adapt to new tasks while retaining\nknowledge from previous ones. Recent advancements in pre-trained models (PTMs)\nhave significantly advanced the field of CIL, demonstrating superior\nperformance over traditional methods. However, understanding how features\nevolve and are distributed across incremental tasks remains an open challenge.\nIn this paper, we propose a novel approach to modeling feature evolution in\nPTM-based CIL through the lens of neural collapse (NC), a striking phenomenon\nobserved in the final phase of training, which leads to a well-separated,\nequiangular feature space. We explore the connection between NC and CIL\neffectiveness, showing that aligning feature distributions with the NC geometry\nenhances the ability to capture the dynamic behavior of continual learning.\nBased on this insight, we introduce Neural Collapse-inspired Pre-Trained\nModel-based CIL (NCPTM-CIL), a method that dynamically adjusts the feature\nspace to conform to the elegant NC structure, thereby enhancing the continual\nlearning process. Extensive experiments demonstrate that NCPTM-CIL outperforms\nstate-of-the-art methods across four benchmark datasets. Notably, when\ninitialized with ViT-B/16-IN1K, NCPTM-CIL surpasses the runner-up method by\n6.73% on VTAB, 1.25% on CIFAR-100, and 2.5% on OmniBenchmark.', 'published': '2025-04-25T15:48:41Z', 'pdf_link': 'http://arxiv.org/pdf/2504.18437v1', 'html_link': 'http://arxiv.org/abs/2504.18437v1', 'categories': ['cs.LG']}]
2025-04-28 23:52:08,272 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-28 23:52:08,741 - INFO - Executed fetch_recent_arxiv with args {'category': 'cs.AI', 'max_results': '1', 'query': ''}, result: [{'title': 'Generalization Capability for Imitation Learning', 'summary': 'Imitation learning holds the promise of equipping robots with versatile\nskills by learning from expert demonstrations. However, policies trained on\nfinite datasets often struggle to generalize beyond the training distribution.\nIn this work, we present a unified perspective on the generalization capability\nof imitation learning, grounded in both information theorey and data\ndistribution property. We first show that the generalization gap can be upper\nbounded by (i) the conditional information bottleneck on intermediate\nrepresentations and (ii) the mutual information between the model parameters\nand the training dataset. This characterization provides theoretical guidance\nfor designing effective training strategies in imitation learning, particularly\nin determining whether to freeze, fine-tune, or train large pretrained encoders\n(e.g., vision-language models or vision foundation models) from scratch to\nachieve better generalization. Furthermore, we demonstrate that high\nconditional entropy from input to output induces a flatter likelihood\nlandscape, thereby reducing the upper bound on the generalization gap. In\naddition, it shortens the stochastic gradient descent (SGD) escape time from\nsharp local minima, which may increase the likelihood of reaching global optima\nunder fixed optimization budgets. These insights explain why imitation learning\noften exhibits limited generalization and underscore the importance of not only\nscaling the diversity of input data but also enriching the variability of\noutput labels conditioned on the same input.', 'published': '2025-04-25T17:59:59Z', 'pdf_link': 'http://arxiv.org/pdf/2504.18538v1', 'html_link': 'http://arxiv.org/abs/2504.18538v1', 'categories': ['cs.LG']}]
